{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Words by Semantic Meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs are placed in Input Folder and Outputs can be checked in Output Folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.cluster import KMeansClusterer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads and returns the list of files from a directory\n",
    "def read_directory(mypath):\n",
    "    current_list_of_files = []\n",
    "\n",
    "    while True:\n",
    "        for (_, _, filenames) in os.walk(mypath):\n",
    "            current_list_of_files = filenames\n",
    "        logging.info(\"Reading the directory for the list of file names\")\n",
    "        return current_list_of_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_subclusters(list_of_terms, name_of_file):\n",
    "\n",
    "    l = [list_of_terms]\n",
    "    \n",
    "    #Converting words to vectors\n",
    "    model = Word2Vec(l, min_count=1)\n",
    "    word_vectors = model.wv.vocab\n",
    "    X = model[word_vectors]\n",
    "    \n",
    "    #Clustering \n",
    "    \n",
    "    NUM_CLUSTERS = 3\n",
    "    kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "    assigned_clusters = kclusterer.cluster(X, assign_clusters=True)\n",
    "    \n",
    "    # Logic for writing the sub-clusters into the file\n",
    "    write = { 0:[], 1:[], 2:[] }\n",
    "    for i, word in enumerate(word_vectors):  \n",
    "        write[assigned_clusters[i]].append(word)\n",
    "            \n",
    "    with open(os.path.join(\"output\",name_of_file), \"w+\") as wt:\n",
    "            for i in write:\n",
    "                st = \" \".join(write[i])\n",
    "                st += '\\n'\n",
    "                wt.write(st)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "\n",
    "    #Folder where the input files are present\n",
    "    mypath = \"input\"\n",
    "    list_of_input_files = read_directory(mypath)\n",
    "    for each_file in list_of_input_files:\n",
    "        with open(os.path.join(mypath,each_file), \"r\") as f:\n",
    "            file_contents = f.read()\n",
    "        list_of_term_in_cluster = file_contents.split()\n",
    "\n",
    "        # Sending the terms to be converted to subclusters in your code\n",
    "        creating_subclusters(list_of_term_in_cluster, each_file)\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
